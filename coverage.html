
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>linkchecker: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">linkchecker/checker.go (100.0%)</option>
				
				<option value="file1">linkchecker/crawler.go (80.0%)</option>
				
				<option value="file2">linkchecker/main.go (35.7%)</option>
				
				<option value="file3">linkchecker/parser.go (93.1%)</option>
				
				<option value="file4">linkchecker/types.go (100.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">// checker.go - URL health checking
package main

import (
        "net/http"
        "sync"
)

// checkURL checks if a URL is accessible and returns status code
func checkURL(client *http.Client, targetURL string) (int, error) <span class="cov8" title="1">{
        resp, err := client.Get(targetURL)
        if err != nil </span><span class="cov8" title="1">{
                return 0, err
        }</span>
        <span class="cov8" title="1">defer resp.Body.Close()
        return resp.StatusCode, nil</span>
}

// checkURLs checks multiple URLs in parallel without crawling
func checkURLs(client *http.Client, urls []string) []LinkResult <span class="cov8" title="1">{
        var results []LinkResult
        var resultsMu sync.Mutex
        var wg sync.WaitGroup

        for _, targetURL := range urls </span><span class="cov8" title="1">{
                wg.Add(1)
                go func(url string) </span><span class="cov8" title="1">{
                        defer wg.Done()

                        status, err := checkURL(client, url)
                        result := LinkResult{
                                URL:       url,
                                SourceURL: "",
                                Status:    status,
                                Error:     err,
                                IsBroken:  err != nil || status &gt;= 400,
                        }

                        resultsMu.Lock()
                        results = append(results, result)
                        resultsMu.Unlock()
                }</span>(targetURL)
        }

        <span class="cov8" title="1">wg.Wait()
        return results</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">// crawler.go - Concurrent web crawling
package main

import (
        "net/http"
        "net/url"
        "sync"
)

// crawl recursively crawls a URL and its links with concurrency
func crawl(client *http.Client, targetURL, sourceURL, baseDomain string, depth int,
        visited *SafeUrlMap, results *[]LinkResult, resultsMu *sync.Mutex, wg *sync.WaitGroup) <span class="cov8" title="1">{

        defer wg.Done()

        // check if already visited
        if visited.Visit(targetURL) </span><span class="cov8" title="1">{
                return
        }</span>

        // check the URL
        <span class="cov8" title="1">resp, err := client.Get(targetURL)

        result := LinkResult{
                URL:       targetURL,
                SourceURL: sourceURL,
        }

        if err != nil </span><span class="cov0" title="0">{
                result.Error = err
                result.IsBroken = true
                resultsMu.Lock()
                *results = append(*results, result)
                resultsMu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">defer resp.Body.Close()

        result.Status = resp.StatusCode
        if resp.StatusCode &gt;= 400 </span><span class="cov8" title="1">{
                result.IsBroken = true
        }</span>

        <span class="cov8" title="1">resultsMu.Lock()
        *results = append(*results, result)
        resultsMu.Unlock()

        // only follow links if same domain and within depth limit
        if !isSameDomain(targetURL, baseDomain) || depth &gt;= maxDepth || resp.StatusCode &gt;= 400 </span><span class="cov8" title="1">{
                return
        }</span>

        // parse base URL for this page
        <span class="cov8" title="1">baseURL, err := url.Parse(targetURL)
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>

        // extract and crawl links
        <span class="cov8" title="1">links, err := extractLinks(resp.Body, baseURL)
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">for _, link := range links </span><span class="cov8" title="1">{
                if isSameDomain(link, baseDomain) </span><span class="cov8" title="1">{
                        // recursively crawl same-domain links in parallel
                        wg.Add(1)
                        go crawl(client, link, targetURL, baseDomain, depth+1, visited, results, resultsMu, wg)
                }</span> else<span class="cov8" title="1"> {
                        // just check external links without following
                        if !visited.Visit(link) </span><span class="cov8" title="1">{
                                wg.Add(1)
                                go func(extLink, srcURL string) </span><span class="cov8" title="1">{
                                        defer wg.Done()

                                        status, err := checkURL(client, extLink)
                                        extResult := LinkResult{
                                                URL:       extLink,
                                                SourceURL: srcURL,
                                                Status:    status,
                                                Error:     err,
                                                IsBroken:  err != nil || status &gt;= 400,
                                        }

                                        resultsMu.Lock()
                                        *results = append(*results, extResult)
                                        resultsMu.Unlock()
                                }</span>(link, targetURL)
                        }
                }
        }
}
</pre>
		
		<pre class="file" id="file2" style="display: none">// main.go - CLI entry point
package main

import (
        "bufio"
        "encoding/json"
        "flag"
        "fmt"
        "net/http"
        "os"
        "strings"
        "sync"
        "time"
)

func main() <span class="cov0" title="0">{
        // define flags
        fileFlag := flag.String("file", "", "File containing URLs to check (one per line)")
        jsonFlag := flag.Bool("json", false, "Output results as JSON for CI/CD integration")
        quietFlag := flag.Bool("quiet", false, "Suppress output, only show errors (useful with -json)")
        timeoutFlag := flag.Duration("timeout", 10*time.Second, "HTTP request timeout (e.g., 10s, 30s, 1m)")
        flag.Parse()

        // get URLs from arguments or file
        var urls []string

        if *fileFlag != "" </span><span class="cov0" title="0">{
                // read URLs from file
                file, err := os.Open(*fileFlag)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "Error opening file: %v\n", err)
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">defer file.Close()

                scanner := bufio.NewScanner(file)
                for scanner.Scan() </span><span class="cov0" title="0">{
                        line := strings.TrimSpace(scanner.Text())
                        if line != "" &amp;&amp; !strings.HasPrefix(line, "#") </span><span class="cov0" title="0">{
                                urls = append(urls, line)
                        }</span>
                }

                <span class="cov0" title="0">if err := scanner.Err(); err != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "Error reading file: %v\n", err)
                        os.Exit(1)
                }</span>
        } else<span class="cov0" title="0"> {
                // get URLs from command line arguments
                urls = flag.Args()
        }</span>

        // validate we have at least one URL
        <span class="cov0" title="0">if len(urls) == 0 </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "Usage: %s [-file &lt;filename&gt;] &lt;url&gt; [url...]\n", os.Args[0])
                fmt.Fprintf(os.Stderr, "\nExamples:\n")
                fmt.Fprintf(os.Stderr, "  %s https://example.com                    # Crawl mode (single URL)\n", os.Args[0])
                fmt.Fprintf(os.Stderr, "  %s https://github.com https://google.com  # Direct check mode (multiple URLs)\n", os.Args[0])
                fmt.Fprintf(os.Stderr, "  %s -file links.txt                        # Check URLs from file\n", os.Args[0])
                os.Exit(1)
        }</span>

        // create HTTP client with configurable timeout
        <span class="cov0" title="0">client := &amp;http.Client{
                Timeout: *timeoutFlag,
        }

        var results []LinkResult

        // mode detection
        if len(urls) == 1 </span><span class="cov0" title="0">{
                // single URL - crawl mode
                startURL := urls[0]
                if !*quietFlag </span><span class="cov0" title="0">{
                        fmt.Printf("üîç Crawling: %s (depth: %d)\n\n", startURL, maxDepth)
                }</span>

                <span class="cov0" title="0">visited := &amp;SafeUrlMap{visited: make(map[string]bool)}
                var resultsMu sync.Mutex
                var wg sync.WaitGroup

                wg.Add(1)
                go crawl(client, startURL, "", startURL, 0, visited, &amp;results, &amp;resultsMu, &amp;wg)
                wg.Wait()</span>
        } else<span class="cov0" title="0"> {
                // multiple URLs - direct check mode
                if !*quietFlag </span><span class="cov0" title="0">{
                        fmt.Printf("üîç Checking %d URLs...\n\n", len(urls))
                }</span>
                <span class="cov0" title="0">results = checkURLs(client, urls)</span>
        }

        // display results
        <span class="cov0" title="0">brokenCount := 0
        for _, result := range results </span><span class="cov0" title="0">{
                if result.IsBroken </span><span class="cov0" title="0">{
                        brokenCount++
                }</span>
        }

        <span class="cov0" title="0">if *jsonFlag </span><span class="cov0" title="0">{
                // JSON output for CI/CD integration
                outputJSON(results, brokenCount)
        }</span> else<span class="cov0" title="0"> {
                // Human-readable output
                outputHuman(results, brokenCount, *quietFlag)
        }</span>

        <span class="cov0" title="0">if brokenCount &gt; 0 </span><span class="cov0" title="0">{
                os.Exit(1)
        }</span>
}

// outputJSON outputs results in JSON format for CI/CD integration
func outputJSON(results []LinkResult, brokenCount int) <span class="cov8" title="1">{
        jsonResults := make([]JSONResult, len(results))
        for i, result := range results </span><span class="cov8" title="1">{
                var errStr *string
                if result.Error != nil </span><span class="cov8" title="1">{
                        s := result.Error.Error()
                        errStr = &amp;s
                }</span>

                <span class="cov8" title="1">jsonResults[i] = JSONResult{
                        URL:       result.URL,
                        Status:    result.Status,
                        Error:     errStr,
                        Broken:    result.IsBroken,
                        SourceURL: result.SourceURL,
                }</span>
        }

        <span class="cov8" title="1">output := JSONOutput{
                Summary: JSONSummary{
                        Total:   len(results),
                        Broken:  brokenCount,
                        Success: len(results) - brokenCount,
                },
                Results: jsonResults,
        }

        encoder := json.NewEncoder(os.Stdout)
        encoder.SetIndent("", "  ")
        if err := encoder.Encode(output); err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "Error encoding JSON: %v\n", err)
                os.Exit(1)
        }</span>
}

// outputHuman outputs results in human-readable format
func outputHuman(results []LinkResult, brokenCount int, quiet bool) <span class="cov8" title="1">{
        if !quiet </span><span class="cov8" title="1">{
                fmt.Println("Results:")
                fmt.Println("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        }</span>

        <span class="cov8" title="1">for _, result := range results </span><span class="cov8" title="1">{
                if result.IsBroken </span><span class="cov8" title="1">{
                        if result.Error != nil </span><span class="cov8" title="1">{
                                fmt.Printf("‚úó [error] %s\n", result.URL)
                                if result.SourceURL != "" </span><span class="cov8" title="1">{
                                        fmt.Printf("  ‚îî‚îÄ Source: %s\n", result.SourceURL)
                                }</span>
                                <span class="cov8" title="1">fmt.Printf("  ‚îî‚îÄ Error: %v\n", result.Error)</span>
                        } else<span class="cov8" title="1"> {
                                fmt.Printf("‚úó [%d] %s\n", result.Status, result.URL)
                                if result.SourceURL != "" </span><span class="cov8" title="1">{
                                        fmt.Printf("  ‚îî‚îÄ Source: %s\n", result.SourceURL)
                                }</span>
                        }
                        <span class="cov8" title="1">fmt.Println()</span>
                } else<span class="cov8" title="1"> if !quiet </span><span class="cov8" title="1">{
                        fmt.Printf("‚úì [%d] %s\n", result.Status, result.URL)
                }</span>
        }

        <span class="cov8" title="1">if !quiet </span><span class="cov8" title="1">{
                fmt.Println("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
                fmt.Printf("Summary: %d checked, %d broken\n", len(results), brokenCount)
        }</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">// parser.go - URL parsing and HTML link extraction
package main

import (
        "io"
        "net/url"
        "strings"

        "golang.org/x/net/html"
)

// isSameDomain checks if two URLs have the same domain
func isSameDomain(url1, url2 string) bool <span class="cov8" title="1">{
        u1, err1 := url.Parse(url1)
        u2, err2 := url.Parse(url2)
        if err1 != nil || err2 != nil </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return u1.Host == u2.Host</span>
}

// extractLinks extracts all links from HTML
func extractLinks(body io.Reader, baseURL *url.URL) ([]string, error) <span class="cov8" title="1">{
        var links []string
        tokenizer := html.NewTokenizer(body)
        linkCount := 0

        for </span><span class="cov8" title="1">{
                tokenType := tokenizer.Next()
                switch tokenType </span>{
                case html.ErrorToken:<span class="cov8" title="1">
                        err := tokenizer.Err()
                        if err == io.EOF </span><span class="cov8" title="1">{
                                return links, nil
                        }</span>
                        <span class="cov0" title="0">return links, err</span>

                case html.StartTagToken, html.SelfClosingTagToken:<span class="cov8" title="1">
                        token := tokenizer.Token()
                        if token.Data == "a" </span><span class="cov8" title="1">{
                                linkCount++
                                for _, attr := range token.Attr </span><span class="cov8" title="1">{
                                        if attr.Key == "href" </span><span class="cov8" title="1">{
                                                link := attr.Val

                                                // skip empty, anchors, and non-http links
                                                if link == "" || link == "#" || strings.HasPrefix(link, "#") ||
                                                        strings.HasPrefix(link, "javascript:") ||
                                                        strings.HasPrefix(link, "mailto:") </span><span class="cov8" title="1">{
                                                        continue</span>
                                                }

                                                // resolve relative URLs
                                                <span class="cov8" title="1">parsedLink, err := url.Parse(link)
                                                if err != nil </span><span class="cov0" title="0">{
                                                        continue</span>
                                                }
                                                <span class="cov8" title="1">absoluteURL := baseURL.ResolveReference(parsedLink)
                                                links = append(links, absoluteURL.String())
                                                break</span>
                                        }
                                }
                        }
                }
        }
}
</pre>
		
		<pre class="file" id="file4" style="display: none">// types.go - Data structures for link checking
package main

import "sync"

const maxDepth = 2 // maximum crawl depth

// LinkResult stores the result of checking a link
type LinkResult struct {
        URL       string
        Status    int
        Error     error
        IsBroken  bool
        SourceURL string
}

// JSONOutput represents the machine-readable output format for CI/CD integration
type JSONOutput struct {
        Summary JSONSummary  `json:"summary"`
        Results []JSONResult `json:"results"`
}

// JSONSummary contains aggregate statistics
type JSONSummary struct {
        Total   int `json:"total"`
        Broken  int `json:"broken"`
        Success int `json:"success"`
}

// JSONResult represents a single link check result
type JSONResult struct {
        URL       string  `json:"url"`
        Status    int     `json:"status"`
        Error     *string `json:"error,omitempty"`
        Broken    bool    `json:"broken"`
        SourceURL string  `json:"source,omitempty"`
}

// SafeUrlMap provides thread-safe access to visited URLs
type SafeUrlMap struct {
        visited map[string]bool
        mu      sync.Mutex
}

// Visit marks a URL as visited, returns true if already visited
func (s *SafeUrlMap) Visit(url string) bool <span class="cov8" title="1">{
        s.mu.Lock()
        defer s.mu.Unlock()

        if s.visited[url] </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">s.visited[url] = true
        return false</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
